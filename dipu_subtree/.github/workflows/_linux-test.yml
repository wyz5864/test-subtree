name: linux-build

on:
  workflow_call:
    inputs:
      test-matrix:
        required: true
        type: string
        description: JSON description of what test configs to run.

env:
  PVC_PATH: '/nvme/share/share/github/cibuild/${{ github.repository }}'
  SOURCE_PATH: '/nvme/share/share/github/sourcecode'
  HOME: "/var/lib/jenkins"
  CI_IMAGE: "registry.sensetime.com/parrots/parrots:linux-bionic-cuda11.7-cudnn8-py3-gcc7"
  BUILD_ENVIRONMENT: "linux-bionic-cuda11.7-py3.10-gcc7"

jobs:
  test:
    name: test
    strategy:
      matrix: ${{ fromJSON(inputs.test-matrix) }}
      fail-fast: false
    runs-on: tps-pytorch-ci
    env:
      CI: "true"
      DEBUG: 0
      TEST_CONFIG: ${{ matrix.config }}
      SHARD_NUMBER: ${{ matrix.shard }}
      NUM_TEST_SHARDS: ${{ matrix.num_shards }}
      GPU_NUM: ${{ matrix.gpu_num }}
    steps:
      - name: test
        run: |
          set -e
          set -o pipefail
          cd ${PVC_PATH}/${GITHUB_RUN_NUMBER}/source && echo '${{ toJSON(env) }}' |grep -v '{\|}'> ${TEST_CONFIG}_${SHARD_NUMBER} && sed -i 's/\"//g' ${TEST_CONFIG}_${SHARD_NUMBER} && sed -i 's/,//g' ${TEST_CONFIG}_${SHARD_NUMBER} && sed -i 's/:[ ]/=\"/g' ${TEST_CONFIG}_${SHARD_NUMBER} && sed -i 's/$/&\"/' ${TEST_CONFIG}_${SHARD_NUMBER} && sed -i 's/^/&export/' ${TEST_CONFIG}_${SHARD_NUMBER}
          export GPU_ID=`python3 ${SOURCE_PATH}/tools/get_gpu.py delete ${GPU_NUM}` && echo "export GPU_ID=${GPU_ID}" >> ${TEST_CONFIG}_${SHARD_NUMBER}
          container_name=$(docker run --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=${GPU_ID} --tty --detach \
          --shm-size=2g --cap-add=SYS_PTRACE \
          -v ${PVC_PATH}/${GITHUB_RUN_NUMBER}/:/home/ \
          -v ${SOURCE_PATH}/tools:${HOME}/tools \
          ${CI_IMAGE} )
          docker exec -t "${container_name}" bash -c "nvidia-smi && source ${HOME}/tools/run.sh && cp -R /home/source ${HOME}/ && cd ${HOME}/source && source ${TEST_CONFIG}_${SHARD_NUMBER} && pip install dist/*.whl && bash .ci/pytorch/test.sh" \
          && python3 ${SOURCE_PATH}/tools/get_gpu.py create ${GPU_ID} && docker rm -f ${container_name} || (python3 ${SOURCE_PATH}/tools/get_gpu.py create ${GPU_ID} &&  docker rm -f ${container_name} && exit 1 )

